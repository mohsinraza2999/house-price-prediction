{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.optim as optim\n",
    "from typing import Tuple, Optional, Callable, Dict\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Abract Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchLayer(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    def forward(self, x: Tensor,\n",
    "        inference: bool = False) -> Tensor:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    def forward(self, x: Tensor,\n",
    "        inference: bool = False) -> Tensor:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mode(m: nn.Module):\n",
    "    m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dense Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "        input_size: int,\n",
    "        neurons: int,\n",
    "        dropout: float = 1.0,\n",
    "        activation: nn.Module = None) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, neurons)\n",
    "        self.activation = activation\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "    def forward(self, x: Tensor,\n",
    "        inference: bool = False) -> Tensor:\n",
    "        if inference:\n",
    "            self.apply(inference_mode)\n",
    "        x = self.linear(x) # does weight multiplication + bias\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePricesModel(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 13,\n",
    "                 hidden_dropout: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = DenseLayer(13, hidden_size,\n",
    "                                 activation=nn.LeakyReLU(),\n",
    "                                 dropout = hidden_dropout)\n",
    "        self.dense2 = DenseLayer(hidden_size, 1)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert x.shape[1] == 13\n",
    "        #print (x.shape)\n",
    "        x = self.dense1(x)\n",
    "        #print (x.shape)\n",
    "        #x = torch.relu(x)\n",
    "        x=self.dense2(x)\n",
    "        #print (x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_boston_model = HousePricesModel(hidden_size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HousePricesModel(\n",
       "  (dense1): DenseLayer(\n",
       "    (linear): Linear(in_features=13, out_features=13, bias=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (dense2): DenseLayer(\n",
       "    (linear): Linear(in_features=13, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_boston_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1161,  0.2549, -0.2232,  0.1615,  0.1684, -0.2127, -0.2572,  0.2313,\n",
      "         -0.1788,  0.2583, -0.2528,  0.1632, -0.2724],\n",
      "        [-0.0869,  0.0140, -0.1359, -0.2326,  0.0968,  0.0863, -0.0754, -0.1270,\n",
      "          0.0500,  0.0160, -0.0395, -0.1867, -0.1331],\n",
      "        [ 0.2119,  0.1605,  0.0913,  0.1344, -0.1211,  0.2240,  0.0979, -0.0859,\n",
      "          0.2736,  0.1194,  0.0536, -0.0279,  0.1028],\n",
      "        [-0.0339, -0.1601, -0.1766, -0.0478, -0.0552, -0.0589,  0.0508,  0.1920,\n",
      "         -0.2404, -0.0229, -0.0023,  0.0919,  0.1200],\n",
      "        [ 0.0732,  0.2084, -0.0282,  0.2294,  0.1782, -0.1331,  0.2262,  0.2004,\n",
      "         -0.2204,  0.1153,  0.0552,  0.1988,  0.0746],\n",
      "        [-0.0332,  0.0297, -0.2716, -0.1184,  0.2442,  0.2214, -0.1933, -0.0117,\n",
      "          0.0275, -0.2170,  0.2670, -0.0357,  0.0356],\n",
      "        [ 0.0071,  0.1674,  0.1698,  0.1024,  0.1326, -0.2241, -0.2290, -0.2202,\n",
      "          0.1618,  0.1108, -0.1682,  0.2672,  0.2300],\n",
      "        [-0.0794,  0.0790,  0.1657, -0.0225, -0.2246,  0.2507, -0.0432, -0.1135,\n",
      "         -0.1470, -0.0641,  0.1844, -0.1322,  0.0900],\n",
      "        [-0.0312,  0.1364,  0.0815, -0.1745, -0.0978,  0.0044,  0.0222,  0.2301,\n",
      "          0.1172, -0.1194, -0.0220,  0.0205,  0.1078],\n",
      "        [ 0.0993, -0.2194,  0.1383, -0.1376,  0.0090, -0.0568, -0.0744,  0.1608,\n",
      "         -0.2759,  0.1998,  0.1198, -0.1059,  0.0471],\n",
      "        [ 0.2427, -0.1038,  0.2528, -0.2401,  0.0058,  0.1275, -0.2142,  0.1902,\n",
      "         -0.2290,  0.1398, -0.1771, -0.2648,  0.2725],\n",
      "        [-0.1221, -0.2054, -0.2284,  0.1593, -0.1925,  0.1364,  0.1804, -0.2085,\n",
      "         -0.0918, -0.0888, -0.0334,  0.1070,  0.2299],\n",
      "        [ 0.0831, -0.2294,  0.0767,  0.2758,  0.2234, -0.0409, -0.2041,  0.2642,\n",
      "         -0.2459,  0.2350,  0.0767,  0.2699,  0.1673]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1459,  0.1983,  0.0897,  0.1707,  0.1906,  0.2289, -0.2104,  0.1096,\n",
      "        -0.2599, -0.2456, -0.0765, -0.0846, -0.0635], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2621, -0.2163,  0.0601,  0.0796, -0.2337, -0.2067, -0.1602,  0.0144,\n",
      "         -0.0233,  0.2059,  0.1372, -0.2536, -0.2131]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0290], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in pytorch_boston_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePricesModel1(PyTorchModel):\n",
    "    def __init__(self,\n",
    "        hidden_size: int = 13):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(13, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert x.shape[1] == 13\n",
    "        #print (x.shape)\n",
    "        x = self.fc1(x)\n",
    "        #print (x.shape)\n",
    "        x = torch.relu(x)\n",
    "        #print (x.shape)\n",
    "        x=self.fc2(x)\n",
    "        #print (x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_boston_model1 = HousePricesModel1(hidden_size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.3666e-04,  3.3997e-02,  2.2908e-01,  4.8672e-03, -6.1186e-02,\n",
      "         -1.9030e-01,  1.9535e-01, -2.3275e-01,  1.4117e-01, -1.3089e-01,\n",
      "         -8.6947e-03,  8.9840e-02,  1.9432e-01],\n",
      "        [ 1.7867e-02,  2.3334e-02, -2.2396e-01, -1.2295e-02,  5.5315e-02,\n",
      "         -1.6663e-01, -2.4244e-01,  6.5674e-03, -1.0359e-01, -1.0692e-02,\n",
      "          2.7040e-01, -1.2615e-02,  9.8212e-02],\n",
      "        [-2.7389e-01,  2.5488e-01,  1.0098e-01,  3.6071e-03,  1.8233e-01,\n",
      "          2.6734e-02,  1.7594e-01,  1.7110e-01,  4.3295e-02,  2.4369e-01,\n",
      "         -1.1354e-01,  2.0075e-01, -1.5876e-01],\n",
      "        [-1.4891e-01,  1.1610e-01, -5.8005e-02,  2.6943e-02, -1.4156e-01,\n",
      "          4.9986e-02, -9.9867e-02,  2.3651e-01,  1.3492e-01, -4.0564e-02,\n",
      "          4.5980e-02,  2.1160e-01, -7.1996e-02],\n",
      "        [-2.0206e-01,  1.1443e-01, -2.7536e-01,  1.2715e-01,  9.0666e-03,\n",
      "         -1.2459e-01, -2.5676e-01, -8.3453e-02, -2.0029e-01, -1.6629e-01,\n",
      "          1.1459e-01,  1.5291e-02, -1.1610e-01],\n",
      "        [-1.4594e-01, -1.5886e-01,  1.8267e-01,  1.6760e-01, -7.3819e-02,\n",
      "         -4.3830e-02, -3.5534e-03,  1.5761e-02,  2.1715e-01, -7.9330e-02,\n",
      "          7.6802e-02,  1.1095e-01, -1.0788e-01],\n",
      "        [-1.5797e-01, -2.9112e-02,  2.5060e-02,  2.6926e-01,  1.0528e-01,\n",
      "         -2.6660e-01, -2.6376e-01,  1.6524e-01, -2.5043e-01, -2.6471e-01,\n",
      "         -2.9178e-02,  2.3575e-01,  1.0801e-01],\n",
      "        [-2.7729e-01,  5.9881e-02,  2.3178e-03, -3.2654e-02,  1.0325e-01,\n",
      "         -2.3184e-01,  1.7073e-01,  2.0912e-01,  1.0221e-01,  1.6301e-01,\n",
      "          8.9524e-02, -2.9575e-02, -1.3562e-01],\n",
      "        [-7.4957e-02, -4.6748e-02,  1.4531e-01,  9.2233e-02, -1.5414e-01,\n",
      "         -2.5405e-01,  1.4673e-01, -2.2143e-01, -1.3807e-01,  1.3577e-01,\n",
      "         -8.6225e-02, -2.2486e-03, -1.8952e-02],\n",
      "        [ 1.3576e-01,  1.7429e-01, -2.7525e-02, -7.9356e-02, -1.1809e-01,\n",
      "         -1.5929e-01, -9.8539e-02,  1.4078e-01, -1.6891e-01, -3.9547e-02,\n",
      "         -5.5095e-02,  1.2155e-01, -2.7167e-01],\n",
      "        [ 2.7240e-01, -4.3469e-02, -4.9935e-03,  1.2542e-01, -2.6664e-01,\n",
      "          1.0855e-01, -1.6243e-01,  1.8910e-01, -3.8649e-02, -2.2468e-01,\n",
      "         -2.5367e-01, -2.5198e-01, -1.8647e-02],\n",
      "        [-1.7352e-01,  2.1141e-01,  1.0455e-01,  1.1366e-01, -8.8933e-03,\n",
      "         -2.6523e-01,  9.8590e-02, -1.0981e-01, -2.3124e-01,  6.7344e-02,\n",
      "          1.2874e-01,  1.8005e-01,  2.5827e-01],\n",
      "        [-6.8282e-02, -2.6113e-01, -1.4542e-01, -9.2968e-02,  2.8684e-02,\n",
      "         -2.5627e-03,  2.7416e-01,  1.1673e-03,  7.7172e-02, -2.3556e-01,\n",
      "          2.5429e-01,  2.4260e-02,  1.7525e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1802, -0.0133, -0.0201,  0.2229,  0.2177,  0.0134, -0.2607, -0.1225,\n",
      "        -0.2703, -0.0399, -0.1934,  0.0503,  0.0911], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0894, -0.2611,  0.2539,  0.1395,  0.0410, -0.0018, -0.1873,  0.2667,\n",
      "          0.0527,  0.2435, -0.2382, -0.2165, -0.1895]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0973], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in pytorch_boston_model1.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchTrainer(object):\n",
    "    def __init__(self,\n",
    "        model: PyTorchModel,\n",
    "        optim: optim.Optimizer,\n",
    "        criterion: nn.MSELoss):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.loss = criterion\n",
    "        self._check_optim_net_aligned()\n",
    "    def _check_optim_net_aligned(self):\n",
    "        assert self.optim.param_groups[0]['params']\\\n",
    "        == list(self.model.parameters())\n",
    "    def _generate_batches(self,\n",
    "        X: Tensor,\n",
    "        y: Tensor,\n",
    "        size: int = 32) -> Tuple[Tensor]:\n",
    "        N = X.shape[0]\n",
    "        for ii in range(0, N, size):\n",
    "            X_batch, y_batch = X[ii:ii+size], y[ii:ii+size]\n",
    "            yield (X_batch, y_batch)\n",
    "    def fit(self, X_train: Tensor, y_train: Tensor,\n",
    "        X_test: Tensor, y_test: Tensor,\n",
    "        epochs: int=100,\n",
    "        eval_every: int=10,\n",
    "        batch_size: int=32) -> PyTorchModel:\n",
    "        for e in range(epochs):\n",
    "            #X_train, y_train = permute_data(X_train, y_train)\n",
    "            #print(X_train.shape,y_train.shape)\n",
    "            batch_generator = self._generate_batches(X_train, y_train,\n",
    "            batch_size)\n",
    "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "                #print(X_batch.shape,y_batch.shape)\n",
    "                self.optim.zero_grad()\n",
    "                output = self.model(X_batch)\n",
    "                loss = self.loss(output, y_batch)\n",
    "                #print(\"b4 grad\",loss)\n",
    "                loss.backward()\n",
    "                #print(\"after grad\",loss)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optim.step()\n",
    "            \n",
    "            self.optim.zero_grad()\n",
    "            output = self.model(X_test)\n",
    "            loss = self.loss(output, y_test)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optim.step()\n",
    "            if e%10==0:\n",
    "                print(\">==> epoch\",e,\">==> loss =\", loss)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "class PyTorchTrainer1:\n",
    "    def __init__(self, model: torch.nn.Module, optim: torch.optim.Optimizer, criterion: torch.nn.Module, device: torch.device):\n",
    "        self.model = model.to(device)\n",
    "        self.optim = optim\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    def _check_params(self):\n",
    "        opt_params = {p for g in self.optim.param_groups for p in g['params']}\n",
    "        model_params = set(self.model.parameters())\n",
    "        missing = model_params - opt_params\n",
    "        if missing:\n",
    "            raise ValueError(f\"Optimizer missing {len(missing)} model params.\")\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, val_loader: DataLoader, epochs: int = 100, eval_every: int = 10, clip_norm: float = 1.0):\n",
    "        self._check_params()\n",
    "        for e in range(1, epochs + 1):\n",
    "            self.model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                out = self.model(xb).squeeze()\n",
    "                loss = self.criterion(out, yb)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                if clip_norm is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_norm)\n",
    "                self.optim.step()\n",
    "\n",
    "            if e % eval_every == 0:\n",
    "                self.model.eval()\n",
    "                val_loss = 0.0\n",
    "                n = 0\n",
    "                with torch.no_grad():\n",
    "                    for xb, yb in val_loader:\n",
    "                        xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                        out = self.model(xb).squeeze()\n",
    "                        val_loss += self.criterion(out, yb).item() * xb.size(0)\n",
    "                        n += xb.size(0)\n",
    "                print(f\"Epoch {e}: val_loss={val_loss / max(n, 1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "class PyTorchTrainer2(object):\n",
    "    def __init__(self,\n",
    "        model: PyTorchModel,\n",
    "        optim: torch.optim.Optimizer,\n",
    "        criterion: torch.nn.Module,\n",
    "        device: torch.device):\n",
    "        self.model = model.to(device)\n",
    "        self.optim = optim\n",
    "        self.criterion = criterion\n",
    "        self.device=device\n",
    "        self._check_optim_net_aligned()\n",
    "    def _check_optim_net_aligned(self):\n",
    "\n",
    "        #model_params = set(p for p in self.model.parameters())\n",
    "        #optim_params = set(p for g in self.optim.param_groups for p in g['params'])\n",
    "        #if not model_params.issubset(optim_params):\n",
    "            #raise ValueError(\"Optimizer missing some model parameters\")\n",
    "\n",
    "\n",
    "        assert self.optim.param_groups[0]['params']\\\n",
    "        == list(self.model.parameters())\n",
    "\n",
    "    def fit(self, train_data: DataLoader, val_data: DataLoader,\n",
    "        epochs: int=100,\n",
    "        eval_every: int=10,\n",
    "        clip_norm:float=1.0):\n",
    "        for e in range(1,epochs+1):\n",
    "\n",
    "            try:\n",
    "                self.model.train()\n",
    "                #X_train, y_train = permute_data(X_train, y_train)\n",
    "                \n",
    "                for X_batch, y_batch in train_data:\n",
    "                    X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                    output = self.model(X_batch).squeeze()\n",
    "                    if output.shape[0] != y_batch.shape[0]:\n",
    "                            raise ValueError(f\"Output {output.shape} != Target {y_batch.shape}\")\n",
    "\n",
    "                    loss = self.criterion(output, y_batch)\n",
    "                    self.optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    #print(\"after grad\",loss)\n",
    "                    if clip_norm is not None:\n",
    "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_norm)\n",
    "                    self.optim.step()\n",
    "                \n",
    "                if e % eval_every == 0:\n",
    "                    #self._evaluate(val_data, metrics, logger, e)\n",
    "                    from sklearn.metrics import mean_absolute_error,r2_score\n",
    "                    #self.model.eval()\n",
    "                    metrics={\"R2_Score\":r2_score,\"MAE\":mean_absolute_error}\n",
    "                    self._evaluate(val_data,metrics=metrics,epoch=e)\n",
    "                    \"\"\"val_loss = 0.0\n",
    "                    n = 0\n",
    "                    with torch.no_grad():\n",
    "                        for xb, yb in val_data:\n",
    "                            xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                            out = self.model(xb).squeeze()\n",
    "                            val_loss += self.criterion(out, yb).item() * xb.size(0)\n",
    "                            n += xb.size(0)\n",
    "                    print(f\"Epoch {e}: val_loss={val_loss / max(n, 1):.4f}\")\"\"\"\n",
    "            \n",
    "            except Exception as ex:\n",
    "                #logger.exception(f\"Training failed at epoch {e}: {ex}\")\n",
    "                raise\n",
    "\n",
    "    def _evaluate(self, val_data: DataLoader,\n",
    "                  metrics: Optional[Dict[str, Callable]] = None,\n",
    "                  logger=None, epoch: int = 0):\n",
    "        self.model.eval()\n",
    "        total_loss, n = 0.0, 0\n",
    "        agg_metrics = {name: 0.0 for name in (metrics or {})}\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_data:\n",
    "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                out = self.model(xb).squeeze()\n",
    "                total_loss += self.criterion(out, yb).item() * xb.size(0)\n",
    "                n += xb.size(0)\n",
    "                if metrics:\n",
    "                    for name, fn in metrics.items():\n",
    "                        agg_metrics[name] += fn(out, yb) * xb.size(0)\n",
    "        avg_loss = total_loss / max(n, 1)\n",
    "        msg = f\"epoch={epoch} val_loss={avg_loss:.4f}\"\n",
    "        if metrics:\n",
    "            for name, total in agg_metrics.items():\n",
    "                msg += f\" {name}={total / max(n, 1):.4f}\"\n",
    "        (logger.info if logger else print)(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'torch.nn.modules.loss.MSELoss'>\n",
      "<class 'str'> <class 'function'>\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def evaluate(metrics: Optional[Dict[str, Callable]] = None):\n",
    "        \n",
    "        agg_metrics = {name: 0.0 for name in (metrics or {})}\n",
    "        if metrics:\n",
    "                    for name, fn in metrics.items():\n",
    "                        print(name.__class__,fn.__class__)\n",
    "        print (agg_metrics[\"MAE\"])\n",
    "metrics={\"MSE\":nn.MSELoss(),\"MAE\":mean_absolute_error}\n",
    "evaluate(metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HousePricesModel(hidden_size=13)\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-4,momentum=0.8)\n",
    "criterion = nn.MSELoss()\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer = PyTorchTrainer2(net, optimizer, criterion, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"E:/ML Model Training/junior level structures/project 1/data/raw/housing.csv\",\n",
    "                 header=None, delimiter=r\"\\s+\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['MEDV']\n",
    "X=data.drop(columns='MEDV',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"E:/ML Model Training/junior level structures/project 1/data/raw/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(data):\n",
    "    data=data.iloc[:, 0]\n",
    "    record_points=[]\n",
    "    for record in data:\n",
    "        \n",
    "        record_points.append(record.replace(\"  \",\" \").replace('  ',' ').split(' ')[1:])\n",
    "\n",
    "    return record_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=pd.DataFrame(data=build_data(data1),columns=column_names, dtype=float)\n",
    "data=data.dropna(axis=0)\n",
    "for c in data.columns:\n",
    "    data[c] = pd.to_numeric(data[c])\n",
    "y=data['MEDV']\n",
    "X=data.drop(columns='MEDV',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0  0.02731  0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8   \n",
       "1  0.02729  0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8   \n",
       "2  0.03237  0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7   \n",
       "3  0.06905  0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7   \n",
       "4  0.02985  0.0   2.18   0.0  0.458  6.430  58.7  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   9.14  21.6  \n",
       "1  392.83   4.03  34.7  \n",
       "2  394.63   2.94  33.4  \n",
       "3  396.90   5.33  36.2  \n",
       "4  394.12   5.21  28.7  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HousePricesModel(\n",
       "  (dense1): DenseLayer(\n",
       "    (linear): Linear(in_features=13, out_features=13, bias=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (dense2): DenseLayer(\n",
       "    (linear): Linear(in_features=13, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0082,  0.0527, -0.0089, -0.1263,  0.1788, -0.0151, -0.1888,  0.0684,\n",
      "         -0.0581, -0.1088, -0.1821, -0.2718, -0.1794],\n",
      "        [-0.1431,  0.0032, -0.1773, -0.2003, -0.2407,  0.0388,  0.1723, -0.1101,\n",
      "          0.2233, -0.2358,  0.1007, -0.1158, -0.1815],\n",
      "        [ 0.1639,  0.2714,  0.2123, -0.2177,  0.1169,  0.2267, -0.2714, -0.0201,\n",
      "          0.0717, -0.1021,  0.1796, -0.1646, -0.2094],\n",
      "        [ 0.0123, -0.2425, -0.2383, -0.2501,  0.0101,  0.0615,  0.2763, -0.0578,\n",
      "         -0.0115, -0.1710, -0.2692,  0.1767, -0.0903],\n",
      "        [ 0.1782, -0.2150,  0.2419, -0.2123, -0.1897, -0.2311, -0.2126, -0.1061,\n",
      "         -0.0763, -0.0030, -0.0165,  0.2203, -0.2225],\n",
      "        [-0.2643,  0.0077, -0.1833, -0.0346, -0.2507, -0.1351,  0.1515, -0.0298,\n",
      "          0.0629, -0.0904, -0.2678,  0.0526,  0.2546],\n",
      "        [ 0.0276,  0.0664, -0.2685, -0.0397,  0.1838,  0.0314, -0.2710,  0.0284,\n",
      "          0.2740, -0.1801,  0.1518, -0.0914, -0.0344],\n",
      "        [ 0.2185, -0.2289, -0.2233, -0.0836, -0.1895, -0.1595,  0.0616,  0.1550,\n",
      "         -0.0848,  0.2738, -0.0215, -0.2578,  0.1981],\n",
      "        [-0.2174, -0.2488, -0.0496,  0.2604,  0.2307,  0.0151,  0.1883,  0.1190,\n",
      "          0.0327,  0.2598, -0.1975, -0.1745, -0.0475],\n",
      "        [-0.1434,  0.2058,  0.2768,  0.2757, -0.2636,  0.1765, -0.2110, -0.1742,\n",
      "          0.1880,  0.2599,  0.0331, -0.1851, -0.2616],\n",
      "        [-0.2148,  0.2239,  0.2247, -0.0758,  0.2650,  0.2385,  0.2348,  0.1743,\n",
      "          0.1047, -0.1717, -0.1726,  0.1725, -0.2472],\n",
      "        [ 0.2557, -0.1518,  0.0106,  0.1690, -0.1693, -0.2641, -0.1213,  0.1727,\n",
      "          0.0255, -0.2463,  0.1964, -0.0021, -0.2440],\n",
      "        [-0.0752,  0.1424, -0.1432, -0.1432, -0.0184,  0.2144, -0.1599,  0.1058,\n",
      "         -0.2276, -0.0086,  0.2773,  0.1151,  0.2054]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2617,  0.1213,  0.2125, -0.1319,  0.1735, -0.2309,  0.1202,  0.2678,\n",
      "        -0.1465, -0.0839, -0.0881,  0.1935, -0.2479], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0423, -0.2520, -0.1557, -0.1338,  0.0965, -0.0342, -0.2556, -0.1597,\n",
      "         -0.0378, -0.2526, -0.1465, -0.1575,  0.1528]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2078], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(torch.tensor(X.values, dtype=torch.float),\n",
    "                                        torch.tensor(y.values, dtype=torch.float)), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(X[0:int(data.shape[0]/4)].values,dtype=torch.float),\n",
    "                                      torch.tensor(y[0:int(data.shape[0]/4)].values, dtype=torch.float)),\n",
    "                                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    lr: float\n",
    "    momentum: float\n",
    "    epochs: int\n",
    "    seed: int = 42\n",
    "    num_workers: int = 4\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self,model:HousePricesModel,optimizer:torch.optim.Optimizer,\n",
    "                 loss_fn:torch.nn.MSELoss,epochs:int, device: torch.device) -> None:\n",
    "        self.model=model\n",
    "        self.optimizer=optimizer\n",
    "        self.loss_fn=loss_fn\n",
    "        self.epochs=epochs\n",
    "        self.device=device\n",
    "\n",
    "    def fit(self,train_data: DataLoader,val_data: DataLoader)-> None:\n",
    "        trainer = PyTorchTrainer2(self.model, self.optimizer, self.loss_fn,self.device)\n",
    "        trainer.fit(train_data, val_data, epochs=self.epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "def training_pipeline(train_data, val_data)-> None:\n",
    "\n",
    "\n",
    "    # Hyperparameters\n",
    "\n",
    "    cfg = TrainConfig(\n",
    "        lr=1e-4,\n",
    "        momentum=0.8,\n",
    "        epochs=200,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    torch.manual_seed(cfg.seed)\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize model, optimizer, and loss function\n",
    "\n",
    "    model = HousePricesModel()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr,\n",
    "                                momentum=cfg.momentum)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Train the model\n",
    "    trainer_object=Train(model=model, optimizer=optimizer,\n",
    "                            loss_fn=criterion, epochs=cfg.epochs,device=device)\n",
    "    trainer_object.fit(train_data,val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_loss=28.3466\n",
      "Epoch 20: val_loss=28.4738\n",
      "Epoch 30: val_loss=29.3723\n",
      "Epoch 40: val_loss=28.4820\n",
      "Epoch 50: val_loss=31.2827\n",
      "Epoch 60: val_loss=32.3281\n",
      "Epoch 70: val_loss=28.7952\n",
      "Epoch 80: val_loss=30.0272\n",
      "Epoch 90: val_loss=30.3701\n",
      "Epoch 100: val_loss=30.9543\n",
      "Epoch 110: val_loss=30.9857\n",
      "Epoch 120: val_loss=29.5851\n",
      "Epoch 130: val_loss=29.1575\n",
      "Epoch 140: val_loss=28.2150\n",
      "Epoch 150: val_loss=30.3258\n",
      "Epoch 160: val_loss=30.2623\n",
      "Epoch 170: val_loss=30.1962\n",
      "Epoch 180: val_loss=28.6153\n",
      "Epoch 190: val_loss=29.0326\n",
      "Epoch 200: val_loss=27.7699\n"
     ]
    }
   ],
   "source": [
    "training_pipeline(train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10 val_loss=4102.5881 R2_Score=-335.8432 MAE=63.7361\n",
      "epoch=20 val_loss=1867.3088 R2_Score=-627.9933 MAE=42.8914\n",
      "epoch=30 val_loss=554.9280 R2_Score=-1050.6934 MAE=22.9467\n",
      "epoch=40 val_loss=50.5903 R2_Score=-13.4861 MAE=5.2212\n",
      "epoch=50 val_loss=38.1482 R2_Score=-7.3826 MAE=5.0536\n",
      "epoch=60 val_loss=37.5108 R2_Score=-6.0265 MAE=5.0615\n",
      "epoch=70 val_loss=38.1600 R2_Score=-5.3995 MAE=5.1165\n",
      "epoch=80 val_loss=37.1008 R2_Score=-4.7660 MAE=5.0028\n",
      "epoch=90 val_loss=36.7830 R2_Score=-4.3365 MAE=4.9599\n",
      "epoch=100 val_loss=36.6534 R2_Score=-4.2076 MAE=4.9550\n",
      "epoch=110 val_loss=33.4353 R2_Score=-3.6673 MAE=4.6556\n",
      "epoch=120 val_loss=33.9627 R2_Score=-3.6792 MAE=4.7160\n",
      "epoch=130 val_loss=34.8682 R2_Score=-3.6871 MAE=4.8078\n",
      "epoch=140 val_loss=32.2933 R2_Score=-3.2711 MAE=4.5595\n",
      "epoch=150 val_loss=32.2615 R2_Score=-3.1775 MAE=4.5613\n",
      "epoch=160 val_loss=32.4259 R2_Score=-3.1860 MAE=4.5819\n",
      "epoch=170 val_loss=32.8817 R2_Score=-3.1456 MAE=4.6299\n",
      "epoch=180 val_loss=33.1065 R2_Score=-3.0897 MAE=4.6557\n",
      "epoch=190 val_loss=31.9603 R2_Score=-2.9081 MAE=4.5375\n",
      "epoch=200 val_loss=31.1380 R2_Score=-2.7972 MAE=4.4565\n"
     ]
    }
   ],
   "source": [
    "model=trainer.fit(train_loader,val_loader,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ML Model Training\\DL_V_EN\\lib\\site-packages\\torch\\nn\\modules\\loss.py:616: UserWarning: Using a target size (torch.Size([126])) that is different to the input size (torch.Size([126, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">==> epoch 0 >==> loss = tensor(394.4746, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 10 >==> loss = tensor(103.7475, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 20 >==> loss = tensor(59.6593, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 30 >==> loss = tensor(56.6137, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 40 >==> loss = tensor(53.2680, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 50 >==> loss = tensor(50.1687, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 60 >==> loss = tensor(47.1748, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 70 >==> loss = tensor(44.1417, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 80 >==> loss = tensor(41.7832, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 90 >==> loss = tensor(39.7318, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 100 >==> loss = tensor(38.3525, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 110 >==> loss = tensor(37.3787, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 120 >==> loss = tensor(36.6337, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model=trainer.fit(X_train=torch.tensor(X.values, dtype=torch.float), y_train=torch.tensor(y.values, dtype=torch.float), \n",
    "            X_test=torch.tensor(X[0:int(data.shape[0]/4)].values,dtype=torch.float), \n",
    "            y_test=torch.tensor(y[0:int(data.shape[0]/4)].values, dtype=torch.float), epochs=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26.2630]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.tensor([[0.02729,\t0.0,\t8.07,\t0.0,\t0.469,\t7.185,\t61.1,\t4.9671,\t2.0,\t242.0,\t17.8,\t392.83,\t4.03]], dtype=torch.float)\n",
    "net(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.PyTorchTrainer object at 0x00000151249FDE20>\n"
     ]
    }
   ],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Readcsv:\n",
    "    def __init__(self,path:str) ->None:\n",
    "        self.path=path\n",
    "    def read(self,name:str)-> pd.Series:\n",
    "        return pd.read_csv(self.path+name)\n",
    "\n",
    "class CleanData(Readcsv):\n",
    "    def __init__(self, path) -> None:\n",
    "        super().__init__(path)\n",
    "\n",
    "    def clean(self,name:str) ->None:\n",
    "        data=self.read(name)\n",
    "        formatted_data=pd.DataFrame(data=self.seprate_columns(data.iloc[:, 0]),columns=column_names)\n",
    "        clean_data=self.drop_missing_values(formatted_data)\n",
    "        structured_data=self.dtype_to_float(clean_data)\n",
    "        self.save_data(structured_data)\n",
    "\n",
    "    def dtype_to_float(self,data:pd.DataFrame) ->pd.DataFrame:\n",
    "\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(float)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def drop_missing_values(self,data:pd.DataFrame) -> pd.DataFrame:\n",
    "        return data.dropna(axis=0)\n",
    "\n",
    "    def seprate_columns(self,data:pd.Series) ->list[str]:\n",
    "        record_points=[]\n",
    "        for record in data:\n",
    "            \n",
    "            record_points.append(record.replace(\"  \",\" \").replace('  ',' ').split(' ')[1:])\n",
    "\n",
    "        return record_points\n",
    "    \n",
    "    def save_data(self,data:pd.DataFrame):\n",
    "        data.to_csv(\"E:/ML Model Training/junior level structures/project 1/data/processed/processed_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=CleanData(\"E:/ML Model Training/junior level structures/project 1/data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n",
      "C:\\Users\\fvcds\\AppData\\Local\\Temp\\ipykernel_10940\\3502790058.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(float)\n"
     ]
    }
   ],
   "source": [
    "obj.clean(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    def __init__(self,path:str)->None:\n",
    "        self.path=path\n",
    "\n",
    "    def read(self,name:str)-> pd.DataFrame:\n",
    "        return pd.read_csv(self.path+name)\n",
    "    \n",
    "class DataMaker(DataReader):\n",
    "    def __init__(self, path)->None:\n",
    "        super().__init__(path)\n",
    "\n",
    "    def make_data(self,name:str)->Tuple[Tuple[torch.Tensor,torch.Tensor],Tuple[torch.Tensor,torch.Tensor]]:\n",
    "        data=self.read(name)\n",
    "        print(\"shape of data :\",data.shape)\n",
    "        y,X=self.get_X_y(data)\n",
    "        print(\"shape of X :\",X.shape)\n",
    "        return self.convert_to_tensor(X[96:],y[96:]),self.convert_to_tensor(X[:96],y[:96])\n",
    "\n",
    "\n",
    "    def get_X_y(self,data:pd.DataFrame) -> Tuple[pd.Series,pd.DataFrame]:\n",
    "        return data['MEDV'],data.drop(columns=['MEDV'],axis=1)\n",
    "    \n",
    "    def convert_to_tensor(self,X:pd.DataFrame,y:pd.Series)->Tuple[torch.Tensor,torch.Tensor]:\n",
    "        return torch.tensor(X.values,dtype=torch.float),torch.tensor(y.values,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob=DataMaker(\"E:/ML Model Training/junior level structures/project 1/data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data : (451, 14)\n",
      "shape of X : (451, 13)\n"
     ]
    }
   ],
   "source": [
    "(X,y),(X_val,y_val)=ob.make_data(\"processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,p=ob.get_X_y(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([355, 13]), torch.Size([355]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self,model:HousePricesModel,optimizer:optim.Optimizer,\n",
    "                 loss_fn:nn.MSELoss,epochs:int):\n",
    "        self.model=model\n",
    "        self.optimizer=optimizer\n",
    "        self.loss_fn=loss_fn\n",
    "        self.epochs=epochs\n",
    "    def fit(self,X:torch.Tensor,y:torch.Tensor,\n",
    "            X_val:torch.Tensor,y_val:torch.Tensor)->PyTorchModel:\n",
    "        trainer = PyTorchTrainer(self.model, self.optimizer, self.loss_fn)\n",
    "        #logger.info(\"Training started...\")\n",
    "        model=trainer.fit(X, y, X_val, y_val, epochs=self.epochs)\n",
    "        return model\n",
    "        #logger.info(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_o=Train(net,optimizer,criterion,201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.2241]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">==> epoch 0 >==> loss = tensor(879.2496, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 10 >==> loss = tensor(278.8664, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 20 >==> loss = tensor(46.6454, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 30 >==> loss = tensor(37.4225, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 40 >==> loss = tensor(36.7412, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 50 >==> loss = tensor(36.4069, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 60 >==> loss = tensor(36.2479, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 70 >==> loss = tensor(36.0693, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 80 >==> loss = tensor(35.8484, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 90 >==> loss = tensor(35.6031, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 100 >==> loss = tensor(35.4262, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 110 >==> loss = tensor(35.2383, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 120 >==> loss = tensor(35.0336, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 130 >==> loss = tensor(34.8232, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 140 >==> loss = tensor(34.6066, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 150 >==> loss = tensor(34.3956, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 160 >==> loss = tensor(34.1669, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 170 >==> loss = tensor(33.9396, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 180 >==> loss = tensor(33.7216, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 190 >==> loss = tensor(33.5208, grad_fn=<MseLossBackward0>)\n",
      ">==> epoch 200 >==> loss = tensor(33.2931, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mo=t_o.fit(X,y,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.4547]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dict1\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masfg\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dict1\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict1={\"a\":\"asfg\"}\n",
    "assert dict1.__class__==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ApiData(BaseModel):\n",
    "    val1: float\n",
    "    val2: float\n",
    "    val3: float\n",
    "    val4: float\n",
    "    val5: float\n",
    "    val6: float\n",
    "    val7: float\n",
    "    val8: float\n",
    "    val9: float\n",
    "    val10: float\n",
    "    val11: float\n",
    "    val12: float\n",
    "    val13:float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def apidata(q: ApiData)-> ApiData:\n",
    "    l=[]\n",
    "    for val in q:\n",
    "        l.append(q[val])\n",
    "\n",
    "    print(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02729, 0.0, 8.07, 0.0, 0.469, 7.185, 61.1, 4.9671, 2.0, 242.0, 17.8, 392.83, 4.03]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w={\"val1\":0.02729,\t\"val2\":0.0,\t\"val3\":8.07,\t\"val4\":0.0,\n",
    "          \"val5\":0.469,\t\"val6\":7.185,\t\"val7\":61.1,\t\"val8\":4.9671,\t\"val9\":2.0,\t\"val10\":242.0,\t\"val11\":17.8,\n",
    "          \"val12\":392.83,\t\"val13\":4.03}\n",
    "\n",
    "z=apidata(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.00',\n",
       " '7.070',\n",
       " '0',\n",
       " '0.4690',\n",
       " '7.1850',\n",
       " '61.10',\n",
       " '4.9671',\n",
       " '2',\n",
       " '242.0',\n",
       " '17.80',\n",
       " '392.83',\n",
       " '4.03',\n",
       " '34.70']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    target_col: str\n",
    "    val_ratio: float = 0.2\n",
    "    seed: int = 42\n",
    "    batch_size: int = 64\n",
    "\n",
    "def read_csv(root: Path, name: str) -> pd.DataFrame:\n",
    "    path = root / name\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"Empty data file: {path}\")\n",
    "    return df\n",
    "\n",
    "def split_shuffle(df: pd.DataFrame, cfg: DatasetConfig) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if cfg.target_col not in df.columns:\n",
    "        raise KeyError(f\"Target column '{cfg.target_col}' not in data.\")\n",
    "    df = df.sample(frac=1.0, random_state=cfg.seed)\n",
    "    n_val = max(1, int(len(df) * cfg.val_ratio))\n",
    "    return df.iloc[n_val:], df.iloc[:n_val]\n",
    "\n",
    "def to_tensors(df: pd.DataFrame, target: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    y = torch.tensor(df[target].values, dtype=torch.float32)\n",
    "    X = torch.tensor(df.drop(columns=[target]).values, dtype=torch.float32)\n",
    "    return X, y\n",
    "\n",
    "class PyTorchTrainer:\n",
    "    def __init__(self, model: torch.nn.Module, optim: torch.optim.Optimizer, criterion: torch.nn.Module, device: torch.device):\n",
    "        self.model = model.to(device)\n",
    "        self.optim = optim\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    def _check_params(self):\n",
    "        opt_params = {p for g in self.optim.param_groups for p in g['params']}\n",
    "        model_params = set(self.model.parameters())\n",
    "        missing = model_params - opt_params\n",
    "        if missing:\n",
    "            raise ValueError(f\"Optimizer missing {len(missing)} model params.\")\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, val_loader: DataLoader, epochs: int = 100, eval_every: int = 10, clip_norm: float = 1.0):\n",
    "        self._check_params()\n",
    "        for e in range(1, epochs + 1):\n",
    "            self.model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                out = self.model(xb).squeeze()\n",
    "                loss = self.criterion(out, yb)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                if clip_norm is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_norm)\n",
    "                self.optim.step()\n",
    "\n",
    "            if e % eval_every == 0:\n",
    "                self.model.eval()\n",
    "                val_loss = 0.0\n",
    "                n = 0\n",
    "                with torch.no_grad():\n",
    "                    for xb, yb in val_loader:\n",
    "                        xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                        out = self.model(xb).squeeze()\n",
    "                        val_loss += self.criterion(out, yb).item() * xb.size(0)\n",
    "                        n += xb.size(0)\n",
    "                print(f\"Epoch {e}: val_loss={val_loss / max(n, 1):.4f}\")\n",
    "\n",
    "    def save(self, path: Path):\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({'model': self.model.state_dict(), 'optimizer': self.optim.state_dict()}, path)\n",
    "\n",
    "# Usage sketch\n",
    "cfg = DatasetConfig(target_col=\"SalePrice\", val_ratio=0.2, seed=123, batch_size=64)\n",
    "df = read_csv(Path(\"data/processed\"), \"processed_data.csv\")\n",
    "train_df, val_df = split_shuffle(df, cfg)\n",
    "X_tr, y_tr = to_tensors(train_df, cfg.target_col)\n",
    "X_val, y_val = to_tensors(val_df, cfg.target_col)\n",
    "train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=cfg.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=cfg.batch_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HousePricesModel()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.8)\n",
    "criterion = torch.nn.MSELoss()\n",
    "trainer = PyTorchTrainer(model, optim, criterion, device)\n",
    "trainer.fit(train_loader, val_loader, epochs=200, eval_every=10)\n",
    "trainer.save(Path(\"models/saved_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    target_col: str\n",
    "    val_ratio: float = 0.2\n",
    "    seed: int = 42\n",
    "    batch_size: int = 64\n",
    "\n",
    "class DataReader:\n",
    "    def __init__(self,root:Path)->None:\n",
    "        self.root=root\n",
    "\n",
    "    def read(self,name:str)-> pd.DataFrame:\n",
    "        path = self.root / name\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "        df=pd.read_csv(path)\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"Empty data file: {path}\")\n",
    "        return df\n",
    "    \n",
    "class DataMaker(DataReader):\n",
    "    def __init__(self, root)->None:\n",
    "        super().__init__(root)\n",
    "\n",
    "    def make_data(self,name:str,\n",
    "                  cfg:DatasetConfig)->Tuple[Tuple[torch.Tensor,torch.Tensor],Tuple[torch.Tensor,torch.Tensor]]:\n",
    "\n",
    "        data=self.read(name)\n",
    "\n",
    "        train_df,val_df=self.split_shuffle(data,cfg)\n",
    "\n",
    "        return self.convert_to_tensor(train_df,cfg.target_col),self.convert_to_tensor(val_df,cfg.target_col)\n",
    "    \n",
    "    def split_shuffle(self,df: pd.DataFrame, cfg: DatasetConfig) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        if cfg.target_col not in df.columns:\n",
    "            raise KeyError(f\"Target column '{cfg.target_col}' not in data.\")\n",
    "        df = df.sample(frac=1.0, random_state=cfg.seed)\n",
    "        n_val = max(1, int(len(df) * cfg.val_ratio))\n",
    "        return df.iloc[n_val:], df.iloc[:n_val]\n",
    "    \n",
    "    def convert_to_tensor(self,df:pd.DataFrame,target_col:str)->Tuple[torch.Tensor,torch.Tensor]:\n",
    "        y = torch.tensor(df[target_col].values, dtype=torch.float32)\n",
    "        X = torch.tensor(df.drop(columns=[target_col]).values, dtype=torch.float32)\n",
    "        return X, y\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_V_EN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
